{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "134a83cc-666b-4792-bde2-f79869ebb8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972c7eee-a09b-4322-af20-f61a13ce0d3e",
   "metadata": {},
   "source": [
    "numpy digunakan untuk operasi array dan perhitungan numerik.\n",
    "random digunakan untuk pengacakan, seperti membuat posisi acak pada papan permainan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8d52169-e814-4376-b9bf-db75f5227678",
   "metadata": {},
   "outputs": [],
   "source": [
    "board_size = 4\n",
    "num_pairs = 8\n",
    "total_states = board_size * board_size\n",
    "episodes = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681383d0-a0ab-41b5-bdbc-ecb928a8bf84",
   "metadata": {},
   "source": [
    "board_size: Ukuran papan (4x4).\n",
    "num_pairs: Jumlah pasangan angka yang harus dicocokkan.\n",
    "total_states: Total jumlah posisi di papan (4×4=164×4=16).\n",
    "episodes: Jumlah iterasi pelatihan untuk algoritme Q-Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9249be-3f4b-42a0-8a64-e205f542c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.1\n",
    "discount_factor = 0.9\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.995\n",
    "min_epsilon = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e22915-69ae-4cd6-a359-db8192c1c9ec",
   "metadata": {},
   "source": [
    "learning_rate: Kecepatan pembelajaran untuk memperbarui nilai Q-Table.\n",
    "discount_factor: Seberapa jauh algoritme mempertimbangkan reward masa depan.\n",
    "epsilon: Parameter untuk eksplorasi, yang akan menurun seiring waktu.\n",
    "epsilon_decay: Faktor penurunan epsilon di setiap episode.\n",
    "min_epsilon: Batas minimal nilai epsilon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae952849-2778-49f4-bc74-e5b5e983fa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_board():\n",
    "    pairs = list(range(1, num_pairs + 1)) * 2\n",
    "    random.shuffle(pairs)\n",
    "    return np.array(pairs).reshape(board_size, board_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d71cf6-c43b-44c6-835f-ee6a16d5f285",
   "metadata": {},
   "source": [
    "Membuat papan permainan dengan pasangan angka acak.\n",
    "Pasangan angka digandakan (karena setiap angka harus dicocokkan) dan diacak menggunakan random.shuffle.\n",
    "Dikembalikan sebagai array 2D dengan ukuran sesuai board_size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf4aa272-0095-40e0-9f8e-497aecc2ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reward(board, pos1, pos2):\n",
    "    if board[pos1] == board[pos2]:\n",
    "        return 10\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91a3340-8b08-408c-a584-a82fbb84bdc0",
   "metadata": {},
   "source": [
    "Menghitung reward berdasarkan pasangan yang dipilih:\n",
    "    Jika angka di posisi pos1 dan pos2 cocok, reward = 10.\n",
    "    Jika tidak cocok, reward = -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5a71a1d-ef11-4455-84c3-b3aab50499e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_action(state, q_table, epsilon):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.randint(0, total_states - 1), random.randint(0, total_states - 1)\n",
    "    else:\n",
    "        return divmod(np.argmax(q_table[state]), board_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e2907-edd5-412e-8a9d-82dd0f5d9fa5",
   "metadata": {},
   "source": [
    "Fungsi ini memilih dua posisi di papan permainan berdasarkan strategi exploration-exploitation:\n",
    "    Jika bilangan acak antara 0 dan 1 lebih kecil dari nilai epsilon, eksplorasi dilakukan dengan memilih dua posisi secara acak.\n",
    "    Jika tidak, eksploitasi dilakukan dengan memilih aksi berdasarkan nilai maksimum dari Q-Table untuk keadaan tertentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "776a4625-3fd4-4f69-8593-4b27aaf5d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros((total_states, total_states))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c57ed851-29c0-44cb-aad8-bb2258d2e3df",
   "metadata": {},
   "source": [
    "Q-Table diinisialisasi sebagai matriks nol dengan ukuran . Matriks ini digunakan untuk menyimpan nilai Q untuk setiap pasangan aksi (dua posisi di papan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cbb91d1c-5203-452b-b6db-15cec3783ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0, Total Reward: -131\n",
      "Episode 20, Total Reward: 13\n",
      "Episode 40, Total Reward: -177\n",
      "Episode 60, Total Reward: -262\n",
      "Episode 80, Total Reward: -332\n",
      "Episode 100, Total Reward: -28\n",
      "Episode 120, Total Reward: -113\n",
      "Episode 140, Total Reward: -396\n",
      "Episode 160, Total Reward: -177\n",
      "Episode 180, Total Reward: -528\n",
      "Training selesai.\n"
     ]
    }
   ],
   "source": [
    "for episode in range(episodes):\n",
    "    board = create_board()\n",
    "    revealed = np.zeros_like(board)\n",
    "    state = random.randint(0, total_states - 1)\n",
    "    total_reward = 0\n",
    "\n",
    "    while not np.all(revealed):\n",
    "        pos1, pos2 = choose_action(state, q_table, epsilon)\n",
    "\n",
    "        while pos1 == pos2:\n",
    "            pos1, pos2 = choose_action(state, q_table, epsilon)\n",
    "\n",
    "        reward = get_reward(board, np.unravel_index(pos1, (board_size, board_size)),\n",
    "                            np.unravel_index(pos2, (board_size, board_size)))\n",
    "\n",
    "        new_state = random.randint(0, total_states - 1)\n",
    "        q_table[state, pos1] += learning_rate * (\n",
    "            reward + discount_factor * np.max(q_table[new_state]) - q_table[state, pos1]\n",
    "        )\n",
    "        q_table[state, pos2] += learning_rate * (\n",
    "            reward + discount_factor * np.max(q_table[new_state]) - q_table[state, pos2]\n",
    "        )\n",
    "\n",
    "        if reward == 10:\n",
    "            revealed[np.unravel_index(pos1, (board_size, board_size))] = 1\n",
    "            revealed[np.unravel_index(pos2, (board_size, board_size))] = 1\n",
    "\n",
    "        total_reward += reward\n",
    "        state = new_state\n",
    "\n",
    "    epsilon = max(min_epsilon, epsilon * epsilon_decay)\n",
    "\n",
    "    if episode % 20 == 0:\n",
    "        print(f\"Episode {episode}, Total Reward: {total_reward}\")\n",
    "\n",
    "print(\"Training selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2c6717-b3ad-44b5-b947-abbfe528e61e",
   "metadata": {},
   "source": [
    "Setiap episode pelatihan dimulai dengan:\n",
    "    Membuat papan permainan baru menggunakan fungsi create_board.\n",
    "    Menginisialisasi array revealed untuk melacak posisi yang sudah ditemukan pasangannya.\n",
    "    Menentukan keadaan awal secara acak.\n",
    "    Mengatur ulang total_reward untuk menyimpan reward yang diterima selama satu episode.\n",
    "\n",
    "Selama semua pasangan di papan belum ditemukan (np.all(revealed) bernilai False), loop ini akan terus berjalan.\n",
    "Dua posisi (pos1pos1 dan pos2pos2) dipilih menggunakan fungsi choose_action. Jika kedua posisi sama, posisi baru dipilih kembali.\n",
    "\n",
    "Reward dihitung menggunakan fungsi get_reward, berdasarkan nilai di dua posisi yang dipilih.\n",
    "Keadaan baru dipilih secara acak.\n",
    "Nilai Q di Q-Table diperbarui untuk kedua posisi yang dipilih menggunakan rumus Q-Learning:\n",
    "Q(s,a)=Q(s,a)+α[r+γmax⁡aQ(s′,a)−Q(s,a)]\n",
    "Q(s,a)=Q(s,a)+α[r+γamax​Q(s′,a)−Q(s,a)]\n",
    "\n",
    "    s: Keadaan saat ini.\n",
    "    a: Aksi yang dipilih (pos1 atau pos2).\n",
    "    r: Reward yang diterima.\n",
    "    s′: Keadaan berikutnya.\n",
    "    α: Learning rate.\n",
    "    γ: Discount factor.\n",
    "Jika pasangan cocok (reward = 10), posisi tersebut ditandai sebagai sudah ditemukan di array revealed.\n",
    "Nilai epsilon dikurangi di setiap episode menggunakan faktor epsilon_decay. Hal ini mengurangi frekuensi eksplorasi seiring dengan berjalannya pelatihan, sehingga model semakin fokus pada eksploitasi.\n",
    "Setiap 20 episode, total reward untuk episode tersebut dicetak untuk memantau kemajuan pelatihan.\n",
    "Setelah semua episode selesai, program mencetak \"Training selesai.\"\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
